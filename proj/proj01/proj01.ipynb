{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2a07e9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"proj01.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf787d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13bbb6d",
   "metadata": {},
   "source": [
    "# Project 1: Regional GDP\n",
    "### Regional Heterogeneity: Varying Economic Performance in US Counties\n",
    "In the first project of Econ 148, we will examine county-level economic performance as measured by real Gross Domestic Product (GDP) over the past two decades. GDP is often analyzed at the country level; however, regional heterogeneity is also a crucial source of variation in growth and business cycle analysis. Therefore, in this project we will use a county-level real GDP dataset from the Bureau of Economic Analysis (BEA) to try to find out the regional differences in economic performance, especially during recessions.\n",
    "\n",
    "You will use the data cleaning and data manipulation skills you have learned so far in this course to wrangle this rich, but rather complex, real-world dataset. \n",
    "\n",
    "#### Data sources: \n",
    "\n",
    "The main dataset we will use in this notebook is [\"CAGDP9: Real GDP in Chained Dollars by County and MSA\"](https://www.bea.gov/data/gdp/gdp-county-metro-and-other-areas) from the Bureau of Economic Analysis (BEA), accessed in January 2023. It provides a comprehensive measure of the gross domestic product of counties, metropolitan statistical areas, and some other local areas in the United States from 2001 to the present. *We use a subset of the full dataset (about 50%) that includes some of the industries available in the original dataset.*\n",
    "\n",
    "We will also use the [\"United States Counties Database\"](https://simplemaps.com/data/us-counties) from Simplemaps.com, accessed Jun 2022. Specifically, we will use the geographic data of U.S. counties (i.e., latitude and longitude) to create the visualizations in the last section. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0d6132",
   "metadata": {},
   "source": [
    "### Learning Objectives: \n",
    "- Importing and exporting dataframes\n",
    "- Metadata of a dataframe\n",
    "- Recognizing and handling missing values and NaNs\n",
    "- String methods and type conversions\n",
    "- Grouping and aggregating\n",
    "- Calculating changes and percentage changes\n",
    "- Joining and merging two dataframes\n",
    "- A demo of using Jupyter widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe399060",
   "metadata": {},
   "source": [
    "**A Note on Grading:**  \n",
    "In Project 1, the autograded questions will have hidden tests, and the text-based free response questions will be graded on correctness. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53635664",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Importing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437646b3",
   "metadata": {},
   "source": [
    "Datasets are encoded in different codecs. In most cases, the default codex (utf-8) will be able to process the datasets. But in other cases, if we run into some issues with decoding (especially with datasets containing symbols or other languages), we can manually specify other codecs (e.g. ascii, latin-1). A complete list of codecs for Python 3.7 and newer can be found [here](https://docs.python.org/3.7/library/codecs.html#standard-encodings). \n",
    "\n",
    "As a side note, if we want to export the dataframe when we are done, we will also want to make sure that we are using the correct codecs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510067be",
   "metadata": {},
   "source": [
    "For example, *some of you may not be able to import the real GDP dataset by BEA* with the default codecs (utf-8). You may get an error message like the one below.\n",
    "```python\n",
    ">>> rgdp = pd.read_csv(\"data/sample_CAGDP9__ALL_AREAS_2001_2021.csv\")\n",
    "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xf1 in position 137852: invalid continuation byte\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03216be0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1.1:** Import the dataset `data/sample_CAGDP9__ALL_AREAS_2001_2021.csv` using an alternative codec `latin-1`.\n",
    "\n",
    "*Hint:* Look up the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) for `pd.read_csv` and see if there is any argument related to codec or encoding. \n",
    "\n",
    "Note: It's totally fine if you see a warning after you successfully import the dataset. This has to do with the content of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2221eb08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rgdp_raw = ...\n",
    "rgdp_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7685b06f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a32d72c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1.2:** We notice that the last four rows in `rgdp_raw` are just some footnotes, so we will drop them. To do so, you can either select the top 47670 rows for the data that we want, or you can drop the bottom 4 rows with [`pandas.DataFrame.drop`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html). Assign the modified dataframe to `rgdp`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad390279",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rgdp = ...\n",
    "rgdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4a0157",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff58169c",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Learn about the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63707d9d",
   "metadata": {},
   "source": [
    "Like we did in Lab 3, one of the first things that we will do with our dataset is to learn about its structure: how many rows and columns are there in the dataset? What values does each column store? What is the data type for each column (int, string, etc.)? For categorical variables, what are unique values? For numerical variables, what is the mean, median, min, and max? \n",
    "\n",
    "In this section, we will use the built-in functions in Pandas to quickly answer the question above. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1963f504",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.1:** How many rows and columns are there in this dataframe `rgdp`? Assign the number of rows to `N_rows` and the number of columns to `N_cols`. \n",
    "\n",
    "Hint: The first section of lab 3 can be a good reference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ede27c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_rows = ...\n",
    "N_cols = ...\n",
    "N_rows, N_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ed86c1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46afaafb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.2:** How many unique GeoFIPS codes are there in this dataframe `rgdp`? Assign the number of unique counties to `N_unique_geofips`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b111f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_unique_geofips = ...\n",
    "N_unique_geofips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b4711a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d7a985",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 2.3:** What do the values in the \"Description\" column represent? Are the categories in the \"Description\" column mutually exclusive, or are they potentially subsets of each other? Give an example to illustrate your point. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6301460c",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74225617",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 2.4:** What are the data types of columns `GeoFIPS`, `GeoName`, `Unit`, and `2021`? Are they integers, floats, strings, objects, or mixed types? Do you find any data types in these columns problematic? Why?\n",
    "\n",
    "*Hint:* Look into `df.dtypes`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eca8e0",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e932cbea",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "---\n",
    "## Part 3: Missing Values and NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dd44b5",
   "metadata": {},
   "source": [
    "The difference between the data found in many tutorials and real-world data is that real-world data is rarely clean and homogeneous. In particular, many interesting datasets will have some amount of missing data. To complicate matters, different data sources may report missing data in different ways."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5b01c8",
   "metadata": {},
   "source": [
    "In our dataset, there are two types of 'missing values': (D) and (NA). Let's see how they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454345a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgdp[rgdp[\"2001\"] == \"(D)\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98af3a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgdp[rgdp[\"2001\"] == \"(NA)\"][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f676860",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 3.1:** Look up the [footnote](https://www.econ148.org/sp23/resources/assets/supp_materials/proj01/CAGDP9__Footnotes.html) of this dataset, what does each of these two types of missing values represent? What do you think is a good way to handle these two types of missing values respectively? This is an open-ended question. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c90a0b0",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eac427",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 3.2:** For the sake of simplicity, simply drop all rows that contain missing values (either (D) or (NA)) for this project. \n",
    "\n",
    "*Note:* This is not good practice, do not do this in the real world.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9c62f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rgdp_no_nans = rgdp.copy()\n",
    "...\n",
    "rgdp_no_nans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f72647f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe47a634",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Type conversions and Regex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9aae1a",
   "metadata": {},
   "source": [
    "In part 2, we noticed that the dataframe we are working with does not have the desired data types for many columns. For example, the real GDP data has some entries that are kept as strings. To convert these entries to the desired data types, the most common way is to use [`pandas.DataFrame.astype(type)`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dfdeec",
   "metadata": {},
   "source": [
    "For example, we can convert the column \"2001\" from strings to integers using `astype(\"int64\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31440dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgdp_no_nans[\"2001\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8691576",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgdp_no_nans[\"2001\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a1122a-0b62-4eed-a03a-6dccba3757a9",
   "metadata": {},
   "source": [
    "It is good practice to perform your data cleaning on a copy of the original dataset, so you can always reference the original dataset if necessary. We create this copy below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e967ae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgdp_clean = rgdp_no_nans.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecaca64",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 4.1:** Write a for-loop that converts all values in the `rgdp_clean` columns ranging from `2001` to `2021`  to `int64`. \n",
    "\n",
    "*Hint:* Be careful when accessing the column labels, they are strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1122a64b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for year in ...:\n",
    "    rgdp_clean[str(year)] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a325ef",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96caf53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if the data types are correct now\n",
    "rgdp_clean.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6e95bf",
   "metadata": {},
   "source": [
    "Now we can see the `dtype` for 2001-2021 are `int64`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9848ffde",
   "metadata": {},
   "source": [
    "We can also convert data type into `float`, `str`, etc. using the `astype` method on the entire dataframe or some specified data series. Pandas also provides a [`pandas.to_numeric()`](https://pandas.pydata.org/docs/reference/api/pandas.to_numeric.html) function to easier convert different data types into numeric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3418f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert LineCode to int64\n",
    "rgdp_clean[\"LineCode\"] = rgdp_clean[\"LineCode\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8aa88d",
   "metadata": {},
   "source": [
    "### Regular Expressions and Strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e2964e",
   "metadata": {},
   "source": [
    "But sometimes the data entries require some manipulation before can be converted to the desirable data types easily. For example, entries in the `GeoFIPS` column in our dataset has the following form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cc67f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgdp_no_nans[\"GeoFIPS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f848214",
   "metadata": {},
   "source": [
    "Note that the quotations are there in the data, so simple conversion like `astype(int)` will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e3e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will produce an error\n",
    "# rgdp_no_nans[\"GeoFIPS\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c142e9",
   "metadata": {},
   "source": [
    "To extract relevant information, we will use regular expressions. A regular expression is a sequence of characters that specifies a search pattern in text. Usually such patterns are used by string-searching algorithms for \"find\" or \"find and replace\" operations on strings, or for input validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a97e1c",
   "metadata": {},
   "source": [
    "For example, we can extract student ID among a bunch of other texts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00145eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_text = \"Name: Oski, Age: 999, SID: 12345678\"\n",
    "re.findall(r\"SID: (\\d*)\", some_text) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0f5eb8",
   "metadata": {},
   "source": [
    "Or we can replace some text we want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b108048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_other_text = \"Stanford is the No.1 university in California. \"\n",
    "re.sub(\"Stanford\", \"UC Berkeley\", some_other_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025a3347",
   "metadata": {},
   "source": [
    "Note that a common way to get rid of texts in a specified pattern is to use [`re.sub`](https://docs.python.org/3/library/re.html#re.sub) and replace the pattern with the empty strings. For example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1130c348",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_messy_text = \"UoskiC Beroskikeleoskiy oskiis oskitheoski No.1oski univoskiersioskity ioskin Calioskifooskirnia.\"\n",
    "re.sub(\"oski\", \"\", some_messy_text) # substitute with the empty string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb4a496",
   "metadata": {},
   "source": [
    "Regular expression is a deep topic and it requires practice to be able to use it well. A well-known website to test if your regular expression works or not is [regex101](https://regex101.com/). It will be very helpful skill in terms of data cleaning. But for now, we will just use it to get rid of the parentheses in data entries in the `GeoFIPS` column. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e7469c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 4.2:** Remove all instances of quotation marks from `too_many_quotation_marks` using regular expressions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fabb74b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "too_many_quotation_marks = 'U\"C B\"er\"kel\"ey i\"s t\"he\" No\".1 u\"niv\"ersity i\"n C\"ali\"fo\"rn\"i\"a.'\n",
    "no_quotation_marks = ...\n",
    "no_quotation_marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262bac88",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759c3879",
   "metadata": {},
   "source": [
    "To apply regex and many other string method to a dataframe, we can use `pandas.Series.str` methods, and apply a string function. In our case [`pandas.Series.str.replace`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.replace.html) that can replace each occurrence of pattern/regex in the Series/Index. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1d62b4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 4.3:** Write the code below that first delete all the quotation marks in values in the `GeoFIPS` column in `rgdp_clean` with [`pandas.Series.str.replace`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.replace.html) and then convert all strings into integers using `astype('int64')`.\n",
    "\n",
    "> **Note:** While we are converting `GeoFIPS` to integers here for convenience and to practice data manipulation techniques, it is important to note that `GeoFIPS` codes are typically handled as **strings** in real-world applications. This is because many FIPS codes contain leading zeros (e.g., `\"01\"` for Alabama), which are essential for accurate identification. Converting them to integers would remove these leading zeros, potentially causing issues when merging datasets or performing lookups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616a1bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rgdp_clean[\"GeoFIPS\"] = ...\n",
    "rgdp_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d670fed",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929827a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgdp_clean.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e884f3",
   "metadata": {},
   "source": [
    "Now everything should be the correct data type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2764dc",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Pivot tables and melt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8404268",
   "metadata": {},
   "source": [
    "You should be familiar with pivot tables from data 8; feel free to review them [here](https://www.data8.org/interactive_table_functions/) if you like. Implementing pivot tables in pandas is fairly similar to implementing them in the datascience package, look at the documentation [here](https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html). Looking at our dataset, it seems like it's already pivoted. So, we would like to introduce you to `.melt()`, which is essentially just the inverse of the pivot table.\n",
    "\n",
    "Many economic datasets are in 'spreadsheet' formats, which have groups of columns representing the same type of information. For example, in our real GDP dataframe, columns like `2001`, `2002` simply give the real GDP values in the given year. To make our lives easier when working with the data later, we can convert this pivoted dataframe to a more traditional dataframe, where all data are in just one column. We can use [`pandas.melt`](https://pandas.pydata.org/docs/reference/api/pandas.melt.html) to do this (in other languages like Stata, this would be called as converting from a wide to a long format)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b789ccc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 5.1:** Convert the dataframe using [`pandas.melt`](https://pandas.pydata.org/docs/reference/api/pandas.melt.html) so that it contains seven columns: `GeoFIPS`, `GeoName`, `Region`, `LineCode`, `Description`, `year`, and `value`. The `value` column should contain the real GDP value for the given region, industry, and year on that row. \n",
    "\n",
    "The first 5 rows of what your resulting dataframe should look like have been provided below in `samp_df`. There are no hidden tests for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153f30cf-30b9-4c1b-bb6a-d1b7753f0c20",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "sample_data = {\n",
    "    'GeoFIPS': [0, 0, 0, 0, 0],\n",
    "    'GeoName': ['United States', 'United States', 'United States', 'United States', 'United States'],\n",
    "    'Region': [\" \",\" \", \" \",\" \", \" \"],\n",
    "    'LineCode': [1.0, 2.0, 3.0, 6.0, 10.0],\n",
    "    'Description': ['All industry total', 'Private industries', 'Agriculture, forestry, fishing and hunting',\n",
    "                    'Mining, quarrying, and oil and gas extraction', 'Utilities'],\n",
    "    'year': [2001, 2001, 2001, 2001, 2001],\n",
    "    'value': [13263417000, 11452473000, 154754000, 272249000, 214832000]\n",
    "}\n",
    "\n",
    "samp_df = pd.DataFrame(sample_data)\n",
    "samp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27227446",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rgdp_melted = pd.melt(rgdp_clean, \n",
    "                      id_vars=[...], \n",
    "                      # id_vars should be the five columns you want to keep the same from rgdp_clean \n",
    "                      # (aka the columns you don't want to unpivot)\n",
    "                      value_vars=[...]\n",
    "                      # value_vars should be the columns you want to combine, or unpivot\n",
    "                     ).rename(columns={\"variable\": \"year\"}) \n",
    "rgdp_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfd1b34",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b21d45",
   "metadata": {},
   "source": [
    "Now, all the real GDP values are in just one column. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5366a634",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 5.2:** One issue remains: the `year` column has data type as strings. Convert the column into `int64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6452d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "rgdp_melted[\"year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15917331",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b2259e",
   "metadata": {},
   "source": [
    "As we are only concerned about the *county-level* GDP data, we will filter `rgdp_melted` for only the relevant data. Some entries in the dataframe represent state aggregates or national aggregate, and these entries will have a GeoFIPS ending in 000. For example, the code of 00000 represents the entire US; 01000 represents the Alabama state; 01001 represents Autauga--a county in Alabama. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9fe823",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 5.3:** Filter the `rgdp_melted` dataframe for rows that contain real GDP data for **only counties (not aggregates)**. Assign the filtered dataframe to `rgdp_county`. \n",
    "\n",
    "*Hint:* You can get the remainder of a division using the modulo operator % in Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbacb888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "rgdp_county[\"Region\"] = rgdp_county[\"Region\"].astype(int) # we can finally do this!\n",
    "rgdp_county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300ee6cd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53830e92",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 5.4** Now filter the `rgdp_county` dataframe for rows that contain **all industry total** real GDP data for only counties (not aggregates). Assign the filtered dataframe to `rgdp_county_allindustry`, then drop the column `Description`. So in the end `rgdp_county_allindustry` dataframe should have six columns: `GeoFIPS`, `GeoName`, `Region`, `LineCode`, `year`, and `value`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdaec7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rgdp_county_allindustry = ...\n",
    "rgdp_county_allindustry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6518b1ef",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7509e366",
   "metadata": {},
   "source": [
    "Now we have our dataframe consisting of county-level real GDP data of all industries total. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ca19a2",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c5eae5",
   "metadata": {},
   "source": [
    "Groupby's are useful for aggregating data across certain categories. When we use a groupby, we essentially split the Pandas dataframe into smaller subframes (one subframe for each group) and perform aggregation functions on each subframe, outputting one dataframe with the result of the aggregation function on all subframes. Pandas offers several built-in aggregation functions, but we can also choose to define our own if we wish. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8a6fe1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 6.1:** Find the annual average GDP for all industries across all US counties. Assign the result to `rgdp_county_allindustry_mean`. This dataframe should only have two columns: `year` and `value`. \n",
    "\n",
    "*Hint:* `pandas.Dataframe.groupby` may be helpful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f410d475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rgdp_county_allindustry_mean = ...\n",
    "rgdp_county_allindustry_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7a41d1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bddd931",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(rgdp_county_allindustry_mean[\"year\"], rgdp_county_allindustry_mean[\"value\"])\n",
    "plt.xticks(np.arange(2001, 2022, 3))\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Thousands of chained 2012 dollars\")\n",
    "plt.title(\"Mean Real GDP for All Industries across all U.S. Counties (2001-2021)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f20fcd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 6.2:** Repeat the same process as above, but for median GDP instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ba3f50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rgdp_county_allindustry_median = ...\n",
    "rgdp_county_allindustry_median.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d5068c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521471c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(rgdp_county_allindustry_median[\"year\"], rgdp_county_allindustry_median[\"value\"])\n",
    "plt.xticks(np.arange(2001, 2022, 3))\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Thousands of chained 2012 dollars\")\n",
    "plt.title(\"Median Real GDP for All Industries in U.S. Counties (2001-2021)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e366c9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 6.3:** Compare and contrast the annual mean and median real GDP for all US counties. What do they have in common? What differences do they have? Why do you think this is the case? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b589afd",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7: Changes and percent changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fbc960",
   "metadata": {},
   "source": [
    "Analyzing raw changes and percent changes of economic data is pertinent for many economic research and studies. Pandas provides convenient methods for us to obtain raw changes and percent changes between the different rows in a dataframe easily. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131d6879",
   "metadata": {},
   "source": [
    "In this part, we will use [`pd.DataFrame.diff`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.diff.html) and [`pd.DataFrame.pct_change`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pct_change.html) methods to see how median county-level real GDP has changed in each region in U.S. during the past 20 years. We use the same regions as defined by the Bureau of Economic Analysis, as shown below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b7ec11",
   "metadata": {},
   "source": [
    "<img src=\"assets/BEA_regions_iowa_state.jpg\" width=\"600\">\n",
    "</br>\n",
    "<center>U.S. Bureau of Economic Analysis Regions Reference Map</center>\n",
    "<center>Source: <a href=\"https://www.icip.iastate.edu/maps/refmaps/bea\">Iowa State University</a></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb48f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "bea_regions = {1: \"New England\", \n",
    "               2: \"Mideast\", \n",
    "               3: \"Great Lakes\", \n",
    "               4: \"Plains\", \n",
    "               5: \"Southeast\", \n",
    "               6: \"Southwest\", \n",
    "               7: \"Rocky Mountains\", \n",
    "               8: \"Far West\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b7e2b1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 7.1:** Compute the percent changes across the years of median real GDP in the Far West region (coded as 8 in the dataset). The result should have two columns `year` and `value` (containing the percent change), and be stored in `rgdp_far_west_pct_chg`. For example, in `rgdp_far_west_pct_chg`, a row with year 2002 should have a value on the same row that corresponds to the percent change in real GDP from 2001 to 2002. `rgdp_far_west_pct_chg` should not have any rows with NaN values. \n",
    "\n",
    "*Hint:* Consider using [`pd.DataFrame.pct_change`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pct_change.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b970a77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rgdp_far_west = rgdp_county_allindustry[...] # select relevant rows\n",
    "rgdp_far_west_groupby = ... # aggregate data\n",
    "...\n",
    "rgdp_far_west_pct_chg[\"value\"] = ... # find the percent changes\n",
    "rgdp_far_west_pct_chg = ... # drop NaN values\n",
    "rgdp_far_west_pct_chg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9084de8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c62794",
   "metadata": {},
   "source": [
    "Now, the numbers in the `value` column represent the percentage chances. However, their units aren't in percents (i.e. 0.01 represents 1%, not 0.01%). If we would like to convert their units to percents, we would need to multiply by 100."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58fdd9c",
   "metadata": {},
   "source": [
    "Now we will make a plot for all regions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a00889",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 7.2:** Now, we want to find the percent changes of median real GDP in each region with `pd.DataFrame.pct_change`. So, write the code that computes the percent changes of median real GDP in each region. \n",
    "\n",
    "*Hint:* start by copying your code from question 7.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dfece1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "for region in np.sort(rgdp_county_allindustry[\"Region\"].unique()):\n",
    "    ... # Use as many lines as you like\n",
    "    rgdp_region_pct_chg = ...\n",
    "    plt.plot(rgdp_region_pct_chg[\"year\"], \n",
    "             rgdp_region_pct_chg[\"value\"] * 100, # as percentages\n",
    "             label=bea_regions[region]\n",
    "            )\n",
    "    \n",
    "plt.xticks(np.arange(2001, 2022, 3))\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Percent Change\")\n",
    "plt.title(\"Percentage Changes of Median Real GDP for All Industries across Counties in Different Regions\")\n",
    "plt.legend(title=\"Region\", loc=(1.03, 0.58));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23653ec2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "---\n",
    "## Part 8: Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a911e5b7",
   "metadata": {},
   "source": [
    "In this section, we will combine our real GDP dataframe with another dataframe that contains the geographical data of each county, so that we can make some beautiful and informative visualizations in the next section. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0c8b78",
   "metadata": {},
   "source": [
    "First, we will import the new dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c57c880",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_geo = pd.read_csv(\"data/uscounties_geo.csv\")\n",
    "county_geo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a9d38b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 8.1:** Select only `county_fips`, `lat`, `lng`, `population` columns in the `county_geo` dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e86975c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "county_geo = ...\n",
    "county_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b56411",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c200b81",
   "metadata": {},
   "source": [
    "Learn more about GeoFIPS [here](https://en.wikipedia.org/wiki/FIPS_county_code). Note that the `county_fips` column in the new dataset represents the same information as the `GeoFIPS` column in our real GDP dataframe. So, these columns can serve as [foreign keys](https://www.cockroachlabs.com/blog/what-is-a-foreign-key/#:~:text=Foreign%20keys%20link%20data%20in,cross%2Dreferencing%20the%20two%20tables) for each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6abf015",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 8.2:** Merge `rgdp_county_allindustry` with `county_geo` on GeoFIPS. No need to drop the duplicate GeoFIPS column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e7f372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rgdp_county_allindustry_geo = ...\n",
    "rgdp_county_allindustry_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6add7bd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61d3960",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 9: Visualize the regional GDP!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c19d58",
   "metadata": {},
   "source": [
    "Now we have cleaned up our dataset and computed the percent change of GDP for each county. It's time to use this data to show how economic performance vary across different regions! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f02d430",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgdp_county_allindustry_geo_chg = rgdp_county_allindustry_geo.copy()\n",
    "rgdp_county_allindustry_geo_chg[\"value\"] = rgdp_county_allindustry_geo[[\"value\"]].pct_change()\n",
    "rgdp_county_allindustry_geo_chg = rgdp_county_allindustry_geo_chg[rgdp_county_allindustry_geo_chg[\"year\"] != 2001]\n",
    "rgdp_county_allindustry_geo_chg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026c4b35",
   "metadata": {},
   "source": [
    "To eliminate some outliers--some have extreme values for changes between years--we will only work with the data with GDP changes from 10th percentile to 90th percentile. The following function uses a library called [GeoPandas](https://geopandas.org/en/stable/index.html) to plot the changes for a given year and a given industry over a map of the US. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3f5dde-bd22-4d1b-bc63-00b34ac7faa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_counties(data, year, industry=\"All Industries\"):\n",
    "    MIN = np.nanpercentile(data[\"value\"], 10)\n",
    "    MAX = np.nanpercentile(data[\"value\"], 90)\n",
    "\n",
    "    rgdp_county_year = data[data[\"year\"] == year]\n",
    "    rgdp_county_year = rgdp_county_year[(rgdp_county_year[\"value\"] < MAX) & (rgdp_county_year[\"value\"] > MIN)]\n",
    "\n",
    "    geometry = gpd.points_from_xy(rgdp_county_year[\"lng\"], rgdp_county_year[\"lat\"])\n",
    "    \n",
    "    gdf = gpd.GeoDataFrame(rgdp_county_year, geometry=geometry)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16, 9))\n",
    "    world = gpd.read_file('assets/110m_cultural/ne_110m_admin_0_countries_lakes.shp')\n",
    "    world.plot(ax=ax, color='lightgrey')  # The above 2 lines are optional, they add a world map as the background\n",
    "    \n",
    "    plot = gdf.plot(ax=ax, marker='o', markersize=20, alpha=0.8, column='value', \n",
    "                    legend=True, cmap=\"coolwarm\", \n",
    "                    legend_kwds={\"label\": \"Percent Change\", \"shrink\": 0.5, \"orientation\": \"horizontal\", \"pad\": 0.1})\n",
    "    \n",
    "    plt.title(f\"Percentage Changes of Real GDP for {industry} in U.S. Counties ({year})\", size=20)\n",
    "    plt.xlabel(\"Longitude\", size=16)\n",
    "    plt.ylabel(\"Latitude\", size=16)\n",
    "    plt.xlim([-170, -50])\n",
    "    plt.ylim([10, 70])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9246001",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_counties(rgdp_county_allindustry_geo_chg, 2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9198a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_counties(rgdp_county_allindustry_geo_chg, 2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d98eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_counties(rgdp_county_allindustry_geo_chg, 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000118af",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 9.1:** Comment on the results above. Are the economic performance similar or different in each region? Do you find it surprising?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983b956c",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fcc31e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 9.2:** Let's look at the plot for 2008 that shows the regional economic performance in the midst of the Great Recession. The causes of the Great Recession include a combination of vulnerabilities that developed in the financial system, along with a series of triggering events that began with the bursting of the United States housing bubble in 2005–2012. As a sidenote, many empirical works suggest that housing crises usually accompany high levels of mortgage delinquencies (people default on their mortgage). \n",
    "\n",
    "Look at the [county-level change in mortgage delinquency figure](https://www.federalreserve.gov/images/bernanke20080505fig3.jpg) that was used in Ben Bernanke's (the chairman of the Federal Reserve at that time) speech [_Mortgage Delinquencies and Foreclosures_](https://www.federalreserve.gov/newsevents/speech/bernanke20080505a.htm) at the Columbia Business School's 32nd Annual Dinner in May 2008. What is the association between this mortgage delinquency graph and the regional real GDP graph we have above? How can this result potentially inform us about the causes of the Great Recession?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b20199f",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787c95d9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "We can also make some widgets! You will get more practice with this in lab 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b45d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_counties_widgets(industry, year):\n",
    "    rgdp_county_industry = rgdp_county[rgdp_county[\"Description\"] == industry].drop(\"Description\", axis=1)\n",
    "    rgdp_county_industry_geo = rgdp_county_industry.merge(county_geo, left_on=\"GeoFIPS\", right_on=\"county_fips\")\n",
    "    rgdp_county_industry_geo_chg = rgdp_county_industry_geo[rgdp_county_industry_geo[\"year\"] != 2001].copy()\n",
    "    \n",
    "    pct_chg_vals = rgdp_county_industry_geo[[\"value\"]].pct_change()\n",
    "    rgdp_county_industry_geo_chg[\"value\"] = pct_chg_vals.drop(index=np.arange(0, len(pct_chg_vals), 20), axis=0)\n",
    "    \n",
    "    plot_counties(rgdp_county_industry_geo_chg, year, re.sub(\"  \", \"\", industry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbb7079",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "otter_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "i = widgets.Dropdown(options=rgdp_county[\"Description\"].unique(),\n",
    "                     value=\"All industry total\", \n",
    "                     description=\"Industry\", \n",
    "                     layout={'width': 'max-content'})\n",
    "\n",
    "t = widgets.IntSlider(min=2002, max=2020, step=1, \n",
    "                      description=\"Year\", \n",
    "                      layout={'width': '300px'})\n",
    "\n",
    "interact(plot_counties_widgets, industry=i, year=t);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532b129a",
   "metadata": {},
   "source": [
    "**Congratulations!** You're done with Econ 148 Project 1!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca869a40",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0faa01d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40e17fc",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "otter": {
   "OK_FORMAT": true,
   "export_pdf_failure_message": "PDF did not generate, please submit screenshots for questions 2.3, 2.4, 3.1, 7.2, 9.1 and 9.2",
   "require_no_pdf_confirmation": true,
   "tests": {
    "q1_1": {
     "name": "q1_1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert rgdp_raw.shape == (47674, 29)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_2": {
     "name": "q1_2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert rgdp.shape == (47670, 29)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert rgdp.iloc[-1]['GeoName'] != np.nan\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert '98000' in rgdp.iloc[-1]['GeoFIPS']\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_1": {
     "name": "q2_1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(N_rows, int) and N_rows > 0\n",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> assert isinstance(N_cols, int) and N_cols > 0\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_2": {
     "name": "q2_2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 100 < N_unique_geofips < 10000\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3_2": {
     "name": "q3_2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert rgdp_no_nans.shape == (34206, 29)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert not rgdp_no_nans.isnull().values.any()\n",
         "failure_message": "The dataframe should not contain any NaNs.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert not '(D)' in rgdp_no_nans.values\n",
         "failure_message": "The dataframe should not contain any \"(D)\"s.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert not '(NA)' in rgdp_no_nans.values\n",
         "failure_message": "The dataframe should not contain any \"(NA)\"s.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4_1": {
     "name": "q4_1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert np.all([rgdp_clean[str(year)].dtype == 'int64' for year in np.arange(2001, 2022)])\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4_2": {
     "name": "q4_2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert no_quotation_marks == 'UC Berkeley is the No.1 university in California.'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4_3": {
     "name": "q4_3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert rgdp_clean['GeoFIPS'].dtypes == 'int64'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(len(rgdp_clean['GeoFIPS'].unique()), 3166)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5_1": {
     "name": "q5_1",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert rgdp_melted.shape == (718326, 7)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.all(rgdp_melted.columns == ['GeoFIPS', 'GeoName', 'Region', 'LineCode', 'Description', 'year', 'value'])\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(rgdp_melted[(rgdp_melted['year'] == '2001') & (rgdp_melted['GeoFIPS'] == 0) & (rgdp_melted['LineCode'] == 1)]['value'].iloc[0], 13263417000)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5_2": {
     "name": "q5_2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert rgdp_melted['year'].dtype == 'int64'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5_3": {
     "name": "q5_3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert rgdp_county.shape == (699426, 7)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.all(rgdp_county.columns == ['GeoFIPS', 'GeoName', 'Region', 'LineCode', 'Description', 'year', 'value'])\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(rgdp_county[(rgdp_county['year'] == 2020) & (rgdp_county['GeoFIPS'] == 56045)]['value'].iloc[0], 292568)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5_4": {
     "name": "q5_4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert rgdp_county_allindustry.shape == (65226, 6)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.all(rgdp_county_allindustry.columns == ['GeoFIPS', 'GeoName', 'Region', 'LineCode', 'year', 'value'])\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.min(rgdp_county_allindustry['LineCode']) == np.max(rgdp_county_allindustry['LineCode'])\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(rgdp_county_allindustry[(rgdp_county_allindustry['year'] == 2020) & (rgdp_county_allindustry['GeoFIPS'] == 56045)]['value'].iloc[0], 292568)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6_1": {
     "name": "q6_1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert rgdp_county_allindustry_mean.shape == (21, 2)\n",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> assert np.all(rgdp_county_allindustry_mean.columns == ['year', 'value'])\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6_2": {
     "name": "q6_2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert rgdp_county_allindustry_median.shape == (21, 2)\n",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> assert np.all(rgdp_county_allindustry_median.columns == ['year', 'value'])\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7_1": {
     "name": "q7_1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert rgdp_far_west_pct_chg.shape == (20, 2)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.all(~rgdp_far_west_pct_chg['value'].isnull())\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert rgdp_far_west_pct_chg['value'].iloc[0] < 1\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8_1": {
     "name": "q8_1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert county_geo.shape == (3143, 4)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.all(county_geo.columns == ['county_fips', 'lat', 'lng', 'population'])\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert county_geo[county_geo['county_fips'] == 17031]['lat'].iloc[0] == 41.8401\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8_2": {
     "name": "q8_2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert rgdp_county_allindustry_geo.shape == (64722, 10)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.all([c in rgdp_county_allindustry_geo.columns for c in ['GeoFIPS', 'GeoName', 'Region', 'LineCode', 'year', 'value', 'county_fips', 'lat', 'lng', 'population']])\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
